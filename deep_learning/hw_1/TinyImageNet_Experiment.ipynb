{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tiny ImageNet 图像分类实验\n",
        "\n",
        "本notebook实现了在Tiny ImageNet数据集上的深度学习图像分类实验，包含多种CNN架构和训练策略的比较。\n",
        "\n",
        "## 实验内容\n",
        "- 基础CNN模型\n",
        "- ResNet残差连接\n",
        "- 不同层数和隐藏层维度\n",
        "- 不同池化方式（最大池化/平均池化）\n",
        "- SGD和Adam优化器\n",
        "- L2正则化\n",
        "- 数据增强（随机裁剪、水平翻转）\n",
        "\n",
        "## 数据集信息\n",
        "- Tiny ImageNet-200: 200个类别，每类500张训练图像，50张验证图像\n",
        "- 图像尺寸: 64x64像素\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://mirrors.cloud.tencent.com/pypi/simple\n",
            "Requirement already satisfied: torch in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (2.9.0)\n",
            "Requirement already satisfied: filelock in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (2025.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
            "Looking in indexes: https://mirrors.cloud.tencent.com/pypi/simple\n",
            "Requirement already satisfied: torchvision in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (0.24.0)\n",
            "Requirement already satisfied: numpy in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torchvision) (2.2.6)\n",
            "Requirement already satisfied: torch==2.9.0 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torchvision) (2.9.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torchvision) (12.0.0)\n",
            "Requirement already satisfied: filelock in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (2025.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from sympy>=1.13.3->torch==2.9.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from jinja2->torch==2.9.0->torchvision) (3.0.3)\n",
            "Looking in indexes: https://mirrors.cloud.tencent.com/pypi/simple\n",
            "Requirement already satisfied: numpy in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (2.2.6)\n",
            "Looking in indexes: https://mirrors.cloud.tencent.com/pypi/simple\n",
            "Requirement already satisfied: pandas in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (2.3.3)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Looking in indexes: https://mirrors.cloud.tencent.com/pypi/simple\n",
            "Requirement already satisfied: matplotlib in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (3.10.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from matplotlib) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from matplotlib) (12.0.0)\n",
            "Requirement already satisfied: pyparsing>=3 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Looking in indexes: https://mirrors.cloud.tencent.com/pypi/simple\n",
            "Requirement already satisfied: scikit-learn in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (1.7.2)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from scikit-learn) (2.2.6)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /llmchat/daixunlian/class_project/class/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入必要的库\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import time\n",
        "import argparse\n",
        "from Imagenet_loader import TinyImageNet\n",
        "from model_utils import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 数据加载和预处理\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "加载Tiny ImageNet-200数据集...\n",
            "训练集批次数量: 1562\n",
            "测试集批次数量: 157\n",
            "类别数量: 200\n",
            "批次大小: 64\n"
          ]
        }
      ],
      "source": [
        "# Tiny ImageNet数据加载器\n",
        "def tiny_loader(batch_size, data_dir):\n",
        "    num_label = 200\n",
        "    normalize = transforms.Normalize((0.4802, 0.4481, 0.3975), (0.2770, 0.2691, 0.2821))\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(32), \n",
        "        transforms.RandomHorizontalFlip(), \n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Resize(32), \n",
        "        transforms.ToTensor(), \n",
        "        normalize\n",
        "    ])\n",
        "    trainset = TinyImageNet(data_dir, train=True, transform=transform_train)\n",
        "    testset = TinyImageNet(data_dir, train=False, transform=transform_test)\n",
        "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "# 设置随机种子\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"加载Tiny ImageNet-200数据集...\")\n",
        "\n",
        "# 加载数据集\n",
        "train_loader, test_loader = tiny_loader(64, './dataset/tiny-imagenet-200')\n",
        "\n",
        "# 获取类别信息\n",
        "train_dir = './dataset/tiny-imagenet-200/train'\n",
        "classes = sorted([name for name in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, name))])\n",
        "\n",
        "print(f\"训练集批次数量: {len(train_loader)}\")\n",
        "print(f\"测试集批次数量: {len(test_loader)}\")\n",
        "print(f\"类别数量: {len(classes)}\")\n",
        "print(f\"批次大小: 64\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 训练和评估函数\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 训练函数 - 添加早停机制\n",
        "def train(model, train_loader, test_loader, criterion, optimizer, \n",
        "          epochs, device, save_dir, is_l2_loss=False, l2_lambda=0.001,\n",
        "          config_name=\"base\", patience=10):\n",
        "    \"\"\"\n",
        "    训练函数，支持早停机制\n",
        "    \n",
        "    Args:\n",
        "        patience: 早停的耐心值，如果连续patience个epoch准确率没有提升则停止训练\n",
        "    \"\"\"\n",
        "    test_acc = evaluate(model, test_loader, device)\n",
        "\n",
        "    model.train()\n",
        "    \n",
        "    # 记录训练历史\n",
        "    train_losses = []\n",
        "    test_accuracies = []\n",
        "    best_acc = 0.0\n",
        "    best_epoch = 0\n",
        "    epochs_no_improve = 0  # 记录连续多少个epoch没有提升\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"训练配置: {config_name}\")\n",
        "    print(f\"L2正则化: {'是 (λ=' + str(l2_lambda) + ')' if is_l2_loss else '否'}\")\n",
        "    print(f\"早停机制: 启用 (patience={patience})\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            \n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            if is_l2_loss:\n",
        "                l2_reg = torch.tensor(0., device=device)\n",
        "                for param in model.parameters():\n",
        "                    l2_reg += torch.norm(param, 2)\n",
        "                loss += l2_lambda * l2_reg\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            if batch_idx % 100 == 0:\n",
        "                avg_loss = running_loss / 100\n",
        "                train_acc = 100 * correct / total\n",
        "                print(f'Epoch: {epoch+1}/{epochs} | '\n",
        "                      f'Batch: {batch_idx+1}/{len(train_loader)} | '\n",
        "                      f'Loss: {avg_loss:.4f} | '\n",
        "                      f'Train Acc: {train_acc:.2f}%')\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # 评估模型\n",
        "        test_acc = evaluate(model, test_loader, device)\n",
        "        test_accuracies.append(test_acc)\n",
        "        \n",
        "        print(f'\\nEpoch {epoch+1} 完成 - 测试准确率: {test_acc:.2f}%')\n",
        "        \n",
        "        # 检查是否有提升\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            best_epoch = epoch\n",
        "            epochs_no_improve = 0  # 重置计数器\n",
        "            \n",
        "            # 保存最佳模型\n",
        "            save_path = os.path.join(save_dir, f'best_{config_name}.pth')\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'accuracy': test_acc,\n",
        "            }, save_path)\n",
        "            print(f'✓ 最佳模型已保存，准确率: {test_acc:.2f}%')\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(f'准确率未提升 ({epochs_no_improve}/{patience})')\n",
        "            \n",
        "            # 早停检查\n",
        "            if epochs_no_improve >= patience and epoch >= 50:\n",
        "                print(f'\\n{\"=\"*60}')\n",
        "                print(f'早停触发！连续{patience}个epoch准确率未提升')\n",
        "                print(f'最佳准确率: {best_acc:.2f}% (Epoch {best_epoch+1})')\n",
        "                print(f'{\"=\"*60}\\n')\n",
        "                break\n",
        "        \n",
        "        print()  # 空行分隔\n",
        "\n",
        "        # 定期保存检查点\n",
        "        if (epoch + 1) % 50 == 0:\n",
        "            save_path = os.path.join(save_dir, f'{config_name}_epoch{epoch+1}.pth')\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'accuracy': test_acc,\n",
        "            }, save_path)\n",
        "            print(f'检查点已保存: epoch {epoch+1}')\n",
        "    \n",
        "    # 训练结束总结\n",
        "    print(f'\\n{\"=\"*60}')\n",
        "    print(f'训练完成！')\n",
        "    print(f'最终epoch: {epoch+1}')\n",
        "    print(f'最佳准确率: {best_acc:.2f}% (Epoch {best_epoch+1})')\n",
        "    print(f'{\"=\"*60}\\n')\n",
        "    \n",
        "    return test_accuracies, best_acc\n",
        "\n",
        "\n",
        "# 评估函数\n",
        "def evaluate(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# 详细测试函数 - 支持加载最佳模型\n",
        "def detailed_test(model, test_loader, device, classes, save_path=None):\n",
        "    \"\"\"\n",
        "    详细测试函数 - 支持加载最佳模型\n",
        "    \n",
        "    Args:\n",
        "        model: 模型实例\n",
        "        test_loader: 测试数据加载器\n",
        "        device: 设备\n",
        "        classes: 类别名称列表 (200个类别)\n",
        "        save_path: 最佳模型保存路径，如果提供则先加载模型\n",
        "    \"\"\"\n",
        "    \n",
        "    # 如果提供了save_path，先加载最佳模型\n",
        "    if save_path is not None:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"加载最佳模型: {save_path}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        if os.path.exists(save_path):\n",
        "            checkpoint = torch.load(save_path, map_location=device)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            saved_acc = checkpoint.get('accuracy', 'N/A')\n",
        "            saved_epoch = checkpoint.get('epoch', 'N/A')\n",
        "            print(f\"✓ 模型加载成功\")\n",
        "            print(f\"  - 训练epoch: {saved_epoch + 1 if isinstance(saved_epoch, int) else saved_epoch}\")\n",
        "            print(f\"  - 保存时准确率: {saved_acc if isinstance(saved_acc, str) else f'{saved_acc:.2f}%'}\")\n",
        "            print(f\"{'='*60}\\n\")\n",
        "        else:\n",
        "            print(f\"⚠ 警告: 模型文件不存在，使用当前模型状态\")\n",
        "            print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    # 开始详细测试\n",
        "    model.eval()\n",
        "    class_correct = [0] * 200  # Tiny ImageNet有200个类别\n",
        "    class_total = [0] * 200\n",
        "    y_trues, y_preds = [], []\n",
        "    \n",
        "    print(\"正在进行详细测试...\")\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            \n",
        "            y_preds.extend(predicted.cpu().numpy())\n",
        "            y_trues.extend(labels.cpu().numpy())\n",
        "            \n",
        "            c = (predicted == labels)\n",
        "            for i in range(len(labels)):\n",
        "                label = labels[i].item()\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"各类别准确率 (前20个类别):\")\n",
        "    print(\"=\"*50)\n",
        "    for i in range(min(20, len(classes))):\n",
        "        if class_total[i] > 0:\n",
        "            acc = 100 * class_correct[i] / class_total[i]\n",
        "            print(f'{classes[i]:12s}: {acc:5.2f}% ({class_correct[i]}/{class_total[i]})')\n",
        "    \n",
        "    overall_acc = 100 * sum(class_correct) / sum(class_total)\n",
        "    print(f'\\n总体准确率: {overall_acc:.2f}%')\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"分类报告 (前20个类别):\")\n",
        "    print(\"=\"*50)\n",
        "    print(classification_report(y_trues, y_preds, target_names=classes[:20]))\n",
        "    \n",
        "    return y_trues, y_preds, overall_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 可视化函数\n",
        "def plot_confusion_matrix(y_trues, y_preds, classes, save_path):\n",
        "    # 由于类别太多(200个)，我们只显示前20个类别的混淆矩阵\n",
        "    cm = confusion_matrix(y_trues, y_preds)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(15, 15))\n",
        "    disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.title(\"混淆矩阵 (Tiny ImageNet)\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"混淆矩阵已保存到 {save_path}\")\n",
        "\n",
        "def plot_training_history(history_dict, save_path):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    \n",
        "    for config_name, accuracies in history_dict.items():\n",
        "        epochs = range(1, len(accuracies) + 1)\n",
        "        plt.plot(epochs, accuracies, marker='o', label=config_name, linewidth=2)\n",
        "    \n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.ylabel('Test Accuracy (%)', fontsize=12)\n",
        "    plt.title('不同配置的测试准确率比较 (Tiny ImageNet)', fontsize=14)\n",
        "    plt.legend(fontsize=10)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"训练历史图已保存到 {save_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 实验配置和运行\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "使用设备: cuda\n",
            "将运行 7 个实验\n"
          ]
        }
      ],
      "source": [
        "# 设置设备\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"使用设备: {device}\")\n",
        "\n",
        "# 创建输出目录\n",
        "save_dir = './outputs/tiny_imagenet/checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# 实验参数\n",
        "num_epochs = 20\n",
        "learning_rate = 0.001\n",
        "\n",
        "# 实验配置列表\n",
        "experiments = [\n",
        "    {\"name\": \"base_experiment\", \"args\": {}},\n",
        "    {\"name\": \"add_hidden_dim\", \"args\": {\"is_large_hidden\": True}},\n",
        "    {\"name\": \"add_layer_num\", \"args\": {\"is_large_layer\": True}},\n",
        "    {\"name\": \"use_mean_pooling\", \"args\": {\"mean_pooling\": True}},\n",
        "    {\"name\": \"use_resnet\", \"args\": {\"is_resnet\": True}},\n",
        "    {\"name\": \"use_l2_regular\", \"args\": {\"is_l2_loss\": True}},\n",
        "    {\"name\": \"use_adam\", \"args\": {\"use_adam\": True}},\n",
        "]\n",
        "\n",
        "print(f\"将运行 {len(experiments)} 个实验\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "############################################################\n",
            "# 实验 1/7: base_experiment\n",
            "############################################################\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[31], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[1;32m     32\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 33\u001b[0m accuracies, best_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_l2_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mis_l2_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43ml2_lambda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m training_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# 详细测试\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[27], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, epochs, device, save_dir, is_l2_loss, l2_lambda, config_name, patience)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain\u001b[39m(model, train_loader, test_loader, criterion, optimizer, \n\u001b[1;32m      3\u001b[0m           epochs, device, save_dir, is_l2_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, l2_lambda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m      4\u001b[0m           config_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    训练函数，支持早停机制\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m        patience: 早停的耐心值，如果连续patience个epoch准确率没有提升则停止训练\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# 记录训练历史\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[27], line 127\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, test_loader, device)\u001b[0m\n\u001b[1;32m    125\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m    128\u001b[0m         inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    129\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n",
            "File \u001b[0;32m/llmchat/daixunlian/class_project/class/lib/python3.10/site-packages/torch/utils/data/dataloader.py:732\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 732\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    738\u001b[0m ):\n",
            "File \u001b[0;32m/llmchat/daixunlian/class_project/class/lib/python3.10/site-packages/torch/utils/data/dataloader.py:788\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    787\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 788\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    790\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m/llmchat/daixunlian/class_project/class/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m/llmchat/daixunlian/class_project/class/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m/llmchat/daixunlian/class_project/deep_learning/hw_1/Imagenet_loader.py:111\u001b[0m, in \u001b[0;36mTinyImageNet.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m--> 111\u001b[0m     img_path, tgt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    113\u001b[0m     sample \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mread_image(img_path)\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "# 运行实验\n",
        "results = {}\n",
        "\n",
        "for i, exp in enumerate(experiments):\n",
        "    print(f\"\\n{'#'*60}\")\n",
        "    print(f\"# 实验 {i+1}/{len(experiments)}: {exp['name']}\")\n",
        "    print(f\"{'#'*60}\")\n",
        "    \n",
        "    # 创建模型\n",
        "    model = CNNBase(\n",
        "        is_large_hidden=exp['args'].get('is_large_hidden', False),\n",
        "        is_large_layer=exp['args'].get('is_large_layer', False),\n",
        "        pooling_type=exp['args'].get('mean_pooling', False),\n",
        "        is_resnet=exp['args'].get('is_resnet', False),\n",
        "        label_num=200,\n",
        "        input_size=64,\n",
        "        is_imagenet=True\n",
        "    ).to(device)\n",
        "    \n",
        "    # 损失函数和优化器\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if exp['args'].get('use_adam', False):\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    else:\n",
        "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    \n",
        "    config_name = exp['name']\n",
        "    if exp['args'].get('is_l2_loss', False):\n",
        "        config_name += \"_l2reg\"\n",
        "    \n",
        "    # 训练模型\n",
        "    start_time = time.time()\n",
        "    accuracies, best_acc = train(\n",
        "        model, train_loader, test_loader, criterion, optimizer,\n",
        "        epochs=num_epochs, device=device, save_dir=save_dir,\n",
        "        is_l2_loss=exp['args'].get('is_l2_loss', False),\n",
        "        l2_lambda=0.001,\n",
        "        config_name=config_name\n",
        "    )\n",
        "    training_time = time.time() - start_time\n",
        "    \n",
        "    # 详细测试\n",
        "    y_trues, y_preds, final_acc = detailed_test(model, test_loader, device, classes, save_path=os.path.join(save_dir, f'best_{config_name}.pth'))\n",
        "    \n",
        "    # 保存混淆矩阵\n",
        "    cm_path = f'./outputs/tiny_imagenet/confusion_matrix_{config_name}.png'\n",
        "    plot_confusion_matrix(y_trues, y_preds, classes, cm_path)\n",
        "    \n",
        "    # 记录结果\n",
        "    results[exp['name']] = {\n",
        "        'accuracies': accuracies,\n",
        "        'best_acc': best_acc,\n",
        "        'final_acc': final_acc,\n",
        "        'training_time': training_time\n",
        "    }\n",
        "    \n",
        "    print('*'*20)\n",
        "    print(f\"实验 {exp['name']} 最终准确率: {final_acc:.2f}%\")\n",
        "    \n",
        "    # 保存结果到文件\n",
        "    with open('./outputs/tiny_imagenet/experiment_results.txt', 'a') as f:\n",
        "        f.write(f\"Experiment: {exp['name']}, Final Accuracy: {final_acc:.2f}%, Training Time: {training_time:.2f} seconds\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 结果分析和可视化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 绘制训练历史比较图\n",
        "history_dict = {name: data['accuracies'] for name, data in results.items()}\n",
        "plot_training_history(history_dict, './outputs/tiny_imagenet/training_history_comparison.png')\n",
        "\n",
        "# 创建结果汇总表\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"实验结果汇总 (Tiny ImageNet)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"{'实验名称':<20} {'最终准确率':<12} {'最佳准确率':<12} {'训练时间(秒)':<15}\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "for name, data in results.items():\n",
        "    print(f\"{name:<20} {data['final_acc']:<12.2f} {data['best_acc']:<12.2f} {data['training_time']:<15.2f}\")\n",
        "\n",
        "# 找出最佳配置\n",
        "best_exp = max(results.items(), key=lambda x: x[1]['final_acc'])\n",
        "print(f\"\\n最佳配置: {best_exp[0]} (准确率: {best_exp[1]['final_acc']:.2f}%)\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
