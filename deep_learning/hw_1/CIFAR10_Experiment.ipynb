{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CIFAR-10 图像分类实验\n",
        "\n",
        "本notebook实现了在CIFAR-10数据集上的深度学习图像分类实验，包含多种CNN架构和训练策略的比较。\n",
        "\n",
        "## 实验内容\n",
        "- 基础CNN模型\n",
        "- ResNet残差连接\n",
        "- 不同层数和隐藏层维度\n",
        "- 不同池化方式（最大池化/平均池化）\n",
        "- SGD和Adam优化器\n",
        "- L2正则化\n",
        "- 数据增强\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入必要的库\n",
        "import torch\n",
        "import torchvision\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import time\n",
        "import argparse\n",
        "from model_utils import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 数据加载和预处理\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 设置随机种子\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# 数据预处理\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "print(\"加载CIFAR-10数据集...\")\n",
        "\n",
        "# 加载数据集\n",
        "train_dataset = datasets.CIFAR10(root='/Users/daixunlian/workspace/class_project/deep_learning/hw_1/dataset/cifar', \n",
        "                                 train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='/Users/daixunlian/workspace/class_project/deep_learning/hw_1/dataset/cifar', \n",
        "                                train=False, download=True, transform=transform)\n",
        "\n",
        "# 创建数据加载器\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "# CIFAR-10类别名称\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "print(f\"训练集大小: {len(train_dataset)}\")\n",
        "print(f\"测试集大小: {len(test_dataset)}\")\n",
        "print(f\"类别数量: {len(classes)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 展示样本图像\n",
        "def show_sample(train_loader):\n",
        "    \"\"\"展示10个样本\"\"\"\n",
        "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
        "                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "    data_iter = iter(train_loader)\n",
        "    images, labels = next(data_iter)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for i in range(10):\n",
        "        img = (images[i] * 0.5 + 0.5)  # 反归一化\n",
        "        img = img.permute(1, 2, 0).numpy()  # CHW -> HWC\n",
        "\n",
        "        plt.subplot(2, 5, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(class_names[labels[i].item()])\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.suptitle(\"CIFAR-10 Sample Images\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('./outputs/cifar/cifar10_samples.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"样本图像已保存到 cifar10_samples.png\")\n",
        "\n",
        "# 展示样本\n",
        "show_sample(train_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 训练和评估函数\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 训练函数\n",
        "def train(model, train_loader, test_loader, criterion, optimizer, \n",
        "          epochs, device, save_dir, is_l2_loss=False, l2_lambda=0.001,\n",
        "          config_name=\"base\"):\n",
        "    model.train()\n",
        "    \n",
        "    # 记录训练历史\n",
        "    train_losses = []\n",
        "    test_accuracies = []\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"训练配置: {config_name}\")\n",
        "    print(f\"L2正则化: {'是 (λ=' + str(l2_lambda) + ')' if is_l2_loss else '否'}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            \n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            if is_l2_loss:\n",
        "                l2_reg = torch.tensor(0., device=device)\n",
        "                for param in model.parameters():\n",
        "                    l2_reg += torch.norm(param, 2)\n",
        "                loss += l2_lambda * l2_reg\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            if batch_idx % 100 == 99:\n",
        "                avg_loss = running_loss / 100\n",
        "                train_acc = 100 * correct / total\n",
        "                print(f'Epoch: {epoch+1}/{epochs} | '\n",
        "                      f'Batch: {batch_idx+1}/{len(train_loader)} | '\n",
        "                      f'Loss: {avg_loss:.4f} | '\n",
        "                      f'Train Acc: {train_acc:.2f}%')\n",
        "                running_loss = 0.0\n",
        "\n",
        "        test_acc = evaluate(model, test_loader, device)\n",
        "        test_accuracies.append(test_acc)\n",
        "        \n",
        "        print(f'\\nEpoch {epoch+1} 完成 - 测试准确率: {test_acc:.2f}%\\n')\n",
        "        \n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            save_path = os.path.join(save_dir, f'best_{config_name}.pth')\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'accuracy': test_acc,\n",
        "            }, save_path)\n",
        "            print(f'最佳模型已保存，准确率: {test_acc:.2f}%')\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            save_path = os.path.join(save_dir, f'{config_name}_epoch{epoch+1}.pth')\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'accuracy': test_acc,\n",
        "            }, save_path)\n",
        "    \n",
        "    return test_accuracies, best_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 评估函数\n",
        "def evaluate(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# 详细测试函数\n",
        "def detailed_test(model, test_loader, device, classes):\n",
        "    model.eval()\n",
        "    class_correct = [0] * 10\n",
        "    class_total = [0] * 10\n",
        "    y_trues, y_preds = [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            \n",
        "            y_preds.extend(predicted.cpu().numpy())\n",
        "            y_trues.extend(labels.cpu().numpy())\n",
        "            \n",
        "            c = (predicted == labels)\n",
        "            for i in range(len(labels)):\n",
        "                label = labels[i].item()\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"各类别准确率:\")\n",
        "    print(\"=\"*50)\n",
        "    for i in range(10):\n",
        "        if class_total[i] > 0:\n",
        "            acc = 100 * class_correct[i] / class_total[i]\n",
        "            print(f'{classes[i]:12s}: {acc:5.2f}% ({class_correct[i]}/{class_total[i]})')\n",
        "\n",
        "    overall_acc = 100 * sum(class_correct) / sum(class_total)\n",
        "    print(f'\\n总体准确率: {overall_acc:.2f}%')\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"分类报告:\")\n",
        "    print(\"=\"*50)\n",
        "    print(classification_report(y_trues, y_preds, target_names=classes))\n",
        "    \n",
        "    return y_trues, y_preds, overall_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 可视化函数\n",
        "def plot_confusion_matrix(y_trues, y_preds, classes, save_path):\n",
        "    cm = confusion_matrix(y_trues, y_preds)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.title(\"混淆矩阵\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"混淆矩阵已保存到 {save_path}\")\n",
        "\n",
        "def plot_training_history(history_dict, save_path):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    \n",
        "    for config_name, accuracies in history_dict.items():\n",
        "        epochs = range(1, len(accuracies) + 1)\n",
        "        plt.plot(epochs, accuracies, marker='o', label=config_name, linewidth=2)\n",
        "    \n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.ylabel('Test Accuracy (%)', fontsize=12)\n",
        "    plt.title('不同配置的测试准确率比较', fontsize=14)\n",
        "    plt.legend(fontsize=10)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"训练历史图已保存到 {save_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 实验配置和运行\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 设置设备\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"使用设备: {device}\")\n",
        "\n",
        "# 创建输出目录\n",
        "save_dir = './outputs/cifar/checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# 实验参数\n",
        "num_epochs = 20\n",
        "learning_rate = 0.001\n",
        "\n",
        "# 实验配置列表\n",
        "experiments = [\n",
        "    {\"name\": \"base_experiment\", \"args\": {}},\n",
        "    {\"name\": \"add_hidden_dim\", \"args\": {\"is_large_hidden\": True}},\n",
        "    {\"name\": \"add_layer_num\", \"args\": {\"is_large_layer\": True}},\n",
        "    {\"name\": \"use_mean_pooling\", \"args\": {\"mean_pooling\": True}},\n",
        "    {\"name\": \"use_resnet\", \"args\": {\"is_resnet\": True}},\n",
        "    {\"name\": \"use_l2_regular\", \"args\": {\"is_l2_loss\": True}},\n",
        "    {\"name\": \"use_adam\", \"args\": {\"use_adam\": True}},\n",
        "]\n",
        "\n",
        "print(f\"将运行 {len(experiments)} 个实验\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 运行实验\n",
        "results = {}\n",
        "\n",
        "for i, exp in enumerate(experiments):\n",
        "    print(f\"\\n{'#'*60}\")\n",
        "    print(f\"# 实验 {i+1}/{len(experiments)}: {exp['name']}\")\n",
        "    print(f\"{'#'*60}\")\n",
        "    \n",
        "    # 创建模型\n",
        "    model = CNNBase(\n",
        "        is_large_layer=exp['args'].get('is_large_layer', False),\n",
        "        is_large_hidden=exp['args'].get('is_large_hidden', False),\n",
        "        pooling_type=exp['args'].get('mean_pooling', False),\n",
        "        is_resnet=exp['args'].get('is_resnet', False),\n",
        "        label_num=10\n",
        "    ).to(device)\n",
        "    \n",
        "    # 损失函数和优化器\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if exp['args'].get('use_adam', False):\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    else:\n",
        "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    \n",
        "    config_name = exp['name']\n",
        "    if exp['args'].get('is_l2_loss', False):\n",
        "        config_name += \"_l2reg\"\n",
        "    \n",
        "    # 训练模型\n",
        "    start_time = time.time()\n",
        "    accuracies, best_acc = train(\n",
        "        model, train_loader, test_loader, criterion, optimizer,\n",
        "        epochs=num_epochs, device=device, save_dir=save_dir,\n",
        "        is_l2_loss=exp['args'].get('is_l2_loss', False),\n",
        "        l2_lambda=0.001,\n",
        "        config_name=config_name\n",
        "    )\n",
        "    training_time = time.time() - start_time\n",
        "    \n",
        "    # 详细测试\n",
        "    y_trues, y_preds, final_acc = detailed_test(model, test_loader, device, classes)\n",
        "    \n",
        "    # 保存混淆矩阵\n",
        "    cm_path = f'./outputs/cifar/confusion_matrix_{config_name}.png'\n",
        "    plot_confusion_matrix(y_trues, y_preds, classes, cm_path)\n",
        "    \n",
        "    # 记录结果\n",
        "    results[exp['name']] = {\n",
        "        'accuracies': accuracies,\n",
        "        'best_acc': best_acc,\n",
        "        'final_acc': final_acc,\n",
        "        'training_time': training_time\n",
        "    }\n",
        "    \n",
        "    print('*'*20)\n",
        "    print(f\"实验 {exp['name']} 最终准确率: {final_acc:.2f}%\")\n",
        "    \n",
        "    # 保存结果到文件\n",
        "    with open('./outputs/cifar/experiment_results.txt', 'a') as f:\n",
        "        f.write(f\"Experiment: {exp['name']}, Final Accuracy: {final_acc:.2f}%, Training Time: {training_time:.2f} seconds\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 结果分析和可视化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 绘制训练历史比较图\n",
        "history_dict = {name: data['accuracies'] for name, data in results.items()}\n",
        "plot_training_history(history_dict, './outputs/cifar/training_history_comparison.png')\n",
        "\n",
        "# 创建结果汇总表\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"实验结果汇总\")\n",
        "print(\"=\"*80)\n",
        "print(f\"{'实验名称':<20} {'最终准确率':<12} {'最佳准确率':<12} {'训练时间(秒)':<15}\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "for name, data in results.items():\n",
        "    print(f\"{name:<20} {data['final_acc']:<12.2f} {data['best_acc']:<12.2f} {data['training_time']:<15.2f}\")\n",
        "\n",
        "# 找出最佳配置\n",
        "best_exp = max(results.items(), key=lambda x: x[1]['final_acc'])\n",
        "print(f\"\\n最佳配置: {best_exp[0]} (准确率: {best_exp[1]['final_acc']:.2f}%)\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
